{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97ce51b-4344-498a-b798-056bea585ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.yolo_inference import yolo_infer2\n",
    "from lib.yolo_inference import prepare_yolo\n",
    "from lib.yolo_inference import get_bbox\n",
    "from lib.yolo_inference import infer\n",
    "from lib.emotic import Emotic\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6913e2-b55d-445f-8227-330646a6e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"\n",
    "serverPort = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e0941e-e285-4465-91c2-6c0a6a1c5a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0) #0=front-cam, 1=back-cam\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1300)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a7910f-1288-4099-9fec-ebd3d11d3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyServer(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        emotion = detectEmotion()\n",
    "        self.send_response(200)\n",
    "        self.send_header(\"Content-type\", \"text/html\")\n",
    "        self.end_headers()\n",
    "        self.wfile.write(bytes(\"<html><head><title>https://pythonbasics.org</title></head>\", \"utf-8\"))\n",
    "        #self.wfile.write(bytes(\"<p>Request: %s</p>\" % self.path, \"utf-8\"))\n",
    "        self.wfile.write(bytes(\"<body>\", \"utf-8\"))\n",
    "        self.wfile.write(bytes(\"<p>\"+emotion+\"</p>\", \"utf-8\"))\n",
    "        self.wfile.write(bytes(\"</body></html>\", \"utf-8\"))\n",
    "        #self.wfile.write(bytes(\"annoyed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46175e22-47bd-4653-af89-4d0c4fce142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection', \\\n",
    "          'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear','Happiness', \\\n",
    "          'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n",
    "cat2ind = {}\n",
    "ind2cat = {}\n",
    "for idx, emotion in enumerate(cat):\n",
    "    cat2ind[emotion] = idx\n",
    "    ind2cat[idx] = emotion\n",
    "\n",
    "vad = ['Valence', 'Arousal', 'Dominance']\n",
    "ind2vad = {}\n",
    "for idx, continuous in enumerate(vad):\n",
    "    ind2vad[idx] = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d563b26-d6e7-495f-8620-979c4d70777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to normalise the demo image using the statistics of the training data the model was trained on\n",
    "context_mean = [0.4690646, 0.4407227, 0.40508908]\n",
    "context_std = [0.2514227, 0.24312855, 0.24266963]\n",
    "body_mean = [0.43832874, 0.3964344, 0.3706214]\n",
    "body_std = [0.24784276, 0.23621225, 0.2323653]\n",
    "context_norm = [context_mean, context_std]\n",
    "body_norm = [body_mean, body_std]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed4b54e-093b-4a03-a0fe-9f17f44a26dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared yolo model\n"
     ]
    }
   ],
   "source": [
    "model_path = 'experiment/models/'\n",
    "result_path = 'experiment/results/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "yolo = prepare_yolo(model_path)\n",
    "yolo = yolo.to(device)\n",
    "yolo.eval()\n",
    "\n",
    "thresholds = torch.FloatTensor(np.load(os.path.join(result_path, 'val_thresholds.npy'))).to(device) \n",
    "model_context = torch.load(os.path.join(model_path,'model_context1.pth')).to(device)\n",
    "model_body = torch.load(os.path.join(model_path,'model_body1.pth')).to(device)\n",
    "emotic_model = torch.load(os.path.join(model_path,'model_emotic1.pth')).to(device)\n",
    "models = [model_context, model_body, emotic_model]\n",
    "  \n",
    "result_file_path = None\n",
    "return_image = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbf93e6-21d2-4fb4-a3d5-5ef4c5335d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectEmotion():\n",
    "    detectedEmo = \"\" \n",
    "    ret, img = cam.read()    ## predict yolo\n",
    "    image_context = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    emo_vals = {}\n",
    "    try:\n",
    "        bbox_yolo = get_bbox(yolo, device, image_context)\n",
    "        for ipbx, pred_bbox in enumerate(bbox_yolo):\n",
    "            emo_vals[f\"bbox_{ipbx}\"] = {'cont': [], 'cat': None}\n",
    "            pred_cat, pred_cont = infer(context_norm, body_norm, ind2cat, ind2vad, device, thresholds, models, image_context=image_context, bbox=pred_bbox, to_print=False)\n",
    "            '''write_text_vad = list()\n",
    "            for continuous in pred_cont:\n",
    "                write_text_vad.append(str('%.1f' %(continuous)))\n",
    "                emo_vals[f\"bbox_{ipbx}\"]['cont'].append(continuous)\n",
    "            emo_vals[f\"bbox_{ipbx}\"]['cat'] = pred_cat\n",
    "            write_text_vad = 'vad ' + ' '.join(write_text_vad) \n",
    "            image_context = cv2.rectangle(image_context, (pred_bbox[0], pred_bbox[1]),(pred_bbox[2] , pred_bbox[3]), (255, 0, 0), 3)\n",
    "            cv2.putText(image_context, write_text_vad, (pred_bbox[0], pred_bbox[1] - 5), cv2.FONT_HERSHEY_PLAIN, 1, (0,139,139), 2)\n",
    "            for i, emotion in enumerate(pred_cat):\n",
    "                cv2.putText(image_context, emotion, (pred_bbox[0], pred_bbox[1] + (i+1)*12), cv2.FONT_HERSHEY_PLAIN, 1, (0,139,139), 2)'''\n",
    "            detectedEmo = pred_cat[0]\n",
    "    except Exception as e:\n",
    "        #print ('Exception for image ',image_path)\n",
    "        print (e)\n",
    "\n",
    "\n",
    "    #return_image = Image.fromarray(image_context)\n",
    "            ## press q or Esc to quit \n",
    "    #print(xs)\n",
    "    #print(type(r))\n",
    "    #out.write(np.array(return_image))\n",
    "    #opencvImage = cv2.cvtColor(np.array(return_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #cv2.imshow(\"\", opencvImage)'''\n",
    "    #time.sleep(2)\n",
    "    #if (cv2.waitKey(1) & 0xFF == ord(\"q\")) or (cv2.waitKey(1)==27):\n",
    "        #break## close camera\n",
    "    #cam.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return detectedEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32481eae-6a9f-4bda-b653-f9439f40b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started http://localhost:9999\n",
      "'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [30/Sep/2021 08:24:55] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:18] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:22] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:26] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:31] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:36] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:44] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:48] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:53] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:26:57] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:27:01] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:27:06] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:27:10] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:33:33] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:33:37] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:33:41] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:33:45] \"GET /detect HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2021 08:33:49] \"GET /detect HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "webServer = HTTPServer((hostName, serverPort), MyServer)\n",
    "print(\"Server started http://%s:%s\" % (hostName, serverPort))\n",
    "\n",
    "try:\n",
    "    webServer.serve_forever()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "webServer.server_close()\n",
    "cam.release()\n",
    "print(\"Server stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0eee0012-19ea-4402-b15a-ad319b5a8373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d48d65b7-fab4-4213-a86f-3834a39bd23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ccdbf-73d6-4c6d-b423-bfd4cd93b887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
